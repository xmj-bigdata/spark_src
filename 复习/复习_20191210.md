# Spark RPC基础通讯原理
生产消费者模型，基于rpc的消息队列通讯。
Driver端：接收RPC EndPoint，处理 消息分发器 EndPoint
- 生产者
   - 本地 Dispatchor.postMessage 处理
   - 远端RPC NettyHandler Receive() 接收, Dispatchor 
   
   源码分析
   hashMap 记录 EndPointData
   Dispatchor PostMessage()
   data.inBox.post()
   receiver.offer(data)
- 消费者
  - 线程池
  - MessageLoop
  
    - receivers.take()
    - data.inbox.process() 
- 数据存储
    - Dispatchor receiver 所有EndPointData信息， endpoint
# SparkSubmit Driver Master Worker 关系
- SparkSubmit 
    - SubmitClient 向 StandaloneRestServer发送 Submission ，StandaloneRestServe向Master发送RegisterDriver
    - Master接收到请求，遍历workers资源，挑选合适资源
- Driver
    - Driver启动，通过AppClient向Master注册，带 Executor信息 ExecutorBackend 
- Master
    - leader选举
    - 接收Worker注册，管理Worker
    - 接收SparkSubmit 通过 APPClient发送的RegisterDriver请求，调动并发送launchDriver指令给Worker
    - 接收Driver通过appClient发送的RegisterApplication请求，调动并发送launchExecutor指令给Worker  
- Worker
    - 向Master发送心跳
    - 接收指令，launchDriver
    - 接收指令，launchExecutor
# Spark任务调度理论基础

Stage
DAGScheduler
TaskSet
runJob
submitterJob

DAGScheduler 划分stage

生成TaskSet 分给TaskSchedulerImpl是执行

DAGScheduler->eventProccessLoop.jobSubmitted->handlerSuhmitterd.jobSubmit处理

# Driver和Executor先关源码过程
## CoarseGrainedSchedulerBackend
- start（）
注册DriverEndpoint
- makeoffers（）制作伪资源
- launchExecutor（）
遍历TaskSchedulerImplresourceOffers任务，启动
- executorDataMap

## DriverEndpoint
- 接收 executor消息
- 接收TaskSchedulerImpl消息
- 提交任务到Executor

## CoarseGrainedExecutorBackend
- Executor
- Driver
- onStart（）
- statusUpdate()
- receive


## CoarseGrainedShedulerBackend
start()
注册DriverEndpoint
makeOffers()
制作executor资源
launchTask()
去 TasksourceImpl去任务
## DriverEndPoint
- 

## CoarseGrainedExecurorBackend
Executor
Driver
onStart（）
receive()
    launchTask()